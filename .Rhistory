download.file(testUrl, destfile = "./test.csv", method = "curl")
# Reading the data
train <- read.csv("./data/train.csv",na.strings = c("NA", "#DIV/0!"))
# Downloading the data
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainUrl, destfile = "./train.csv", method = "curl")
download.file(testUrl, destfile = "./test.csv", method = "curl")
# Reading the data
train <- read.csv("./train.csv",na.strings = c("NA", "#DIV/0!"))
test <- read.csv("./test.csv",na.strings = c("NA", "#DIV/0!"))
# Downloading the data
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainUrl, destfile = "./train.csv", method = "curl")
download.file(testUrl, destfile = "./test.csv", method = "curl")
# Reading the data
train <- read.csv("./train.csv",na.strings = c("NA", "#DIV/0!"))
test <- read.csv("./test.csv",na.strings = c("NA", "#DIV/0!"))
summary(train)
head(train)
summary(test)
head(train)
head(test)
kable(head(train))
library(knitr)
library(knitr)
kable(head(train))
kabel(head(test))
kable(head(train))
kable(head(test))
View(train)
View(test)
View(test)
View(train)
kable(head(train))
kable(head(test))
dim(train), dim(test)
kable(head(train))
kable(head(test))
dim(train)
dim(test)
str(train)
kable(head(train))
kable(head(test))
dim(train)
dim(test)
# Remove variables with near zero variance
train<-train[,colSums(is.na(train)) == 0]
test <-test[,colSums(is.na(test)) == 0]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(training)
# Remove variables with near zero variance
train<-train[,colSums(is.na(train)) == 0]
test <-test[,colSums(is.na(test)) == 0]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
train<-train[,colSums(is.na(train)) < 1900]
test <-test[,colSums(is.na(test)) < 1900]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(training)) < 1900
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-(1:7)]
test <-test[,-(1:7)]
#The data after cleaning
dim(train)
dim(test)
library(knitr)
# Downloading the data
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainUrl, destfile = "./train.csv", method = "curl")
download.file(testUrl, destfile = "./test.csv", method = "curl")
# Reading the data and filling missing data
train <- read.csv("./train.csv",na.strings = c("NA", "#DIV/0!"))
test <- read.csv("./test.csv",na.strings = c("NA", "#DIV/0!"))
kable(head(train))
kable(head(test))
# Getting the dimensions of the dataframe
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-(1:7)]
test <-test[,-(1:7)]
#The data after cleaning
dim(train)
dim(test)
#In order to get out-of-sample errors, split the training data in training (75%) and testing (25%) data) subsets:
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Remove variables with near zero variance
goodCol <- colSums(is.na(train)) < 1900
train<-train[,goodCol][ , ]
test <-test[,goodCol][ , ]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
# Downloading the data
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#download.file(trainUrl, destfile = "./train.csv", method = "curl")
#(testUrl, destfile = "./test.csv", method = "curl")
# Reading the data and filling missing data
train <- read.csv("./train.csv",na.strings = c("NA", "#DIV/0!"))
test <- read.csv("./test.csv",na.strings = c("NA", "#DIV/0!"))
# Remove variables with near zero variance
#goodCol <- colSums(is.na(train)) < 1900
train<-train[,colSums(is.na(training)) == 0]
# Remove variables with near zero variance
#goodCol <- colSums(is.na(train)) < 1900
train<-train[,colSums(is.na(train)) == 0]
test <-test[,colSums(is.na(test)) == 0]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
#The data after cleaning
dim(train)
dim(test)
install.packages(caret)
"caret"
install.packages("caret")
# Split the training data in training (75%) and testing (25%) data subset
library(caret)
inTrain <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
subTrain <- train[inTrain, ]
subTest <- train[-inTrain, ]
dim(subTrain)
dim(subTest)
# Split the training data in training (75%) and testing (25%) data subset
library(caret)
inTrain <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
subTrain <- train[inTrain, ]
subTest <- train[-inTrain, ]
dim(subTrain)
dim(subTest)
#DECISION TREE
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
install.packages("rpart")
install.packages("rpart")
#DECISION TREE
library(rpart)
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
#Use model to predict class in sub test set
predictionDT <- predict(fitDT, subTest, type = "class")
#Estimate the errors of the prediction algorithm in the Decision Tree model
confusionMatrix(subTest$classe, predictionDT)
install.packages("randomForest")
#DECISION TREE
library(rpart)
library(randomForest)
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
#Use model to predict class in sub test set
predictionDT <- predict(fitDT, subTest, type = "class")
#Estimate the errors of the prediction algorithm in the Decision Tree model
confusionMatrix(subTest$classe, predictionDT)
#DECISION TREE
library(rpart)
library(randomForest)
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
#Use model to predict class in sub test set
predictionDT <- predict(fitDT, subTest, type = "class")
#Estimate the errors of the prediction algorithm in the Decision Tree model
subTest$classe <- as.factor(subTest$classe)
predictionDT <- as.factor(predictionDT)
confusionMatrix(subTest$classe, predictionDT)
install.packages("e1071")
library(e1071)
#DECISION TREE
library(rpart)
library(randomForest)
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
#Use model to predict class in sub test set
predictionDT <- predict(fitDT, subTest, type = "class")
#Estimate the errors of the prediction algorithm in the Decision Tree model
subTest$classe <- as.factor(subTest$classe)
predictionDT <- as.factor(predictionDT)
confusionMatrix(subTest$classe, predictionDT)
#RANDOM FOREST
#Fit model on NEOTraining data
fitRF <- randomForest(classe ~ ., data=subTrain, method="class")
#DECISION TREE
library(rpart)
library(randomForest)
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
#Use model to predict class in sub test set
predictionDT <- predict(fitDT, subTest, type = "class")
#Estimate the errors of the prediction algorithm in the Decision Tree model
subTest$classe <- as.numeric(subTest$classe)
predictionDT <- as.numeric(predictionDT)
confusionMatrix(subTest$classe, predictionDT)
#DECISION TREE
library(rpart)
library(randomForest)
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
#Use model to predict class in sub test set
predictionDT <- predict(fitDT, subTest, type = "class")
#Estimate the errors of the prediction algorithm in the Decision Tree model
subTest$classe <- as.factor(subTest$classe)
predictionDT <- as.factor(predictionDT)
confusionMatrix(subTest$classe, predictionDT)
#DECISION TREE
library(rpart)
library(randomForest)
#Fit model on the sub training data
fitDT <- rpart(classe ~ ., data=subTrain, method="class")
#Use model to predict class in sub test set
predictionDT <- predict(fitDT, subTest, type = "class")
#Estimate the errors of the prediction algorithm in the Decision Tree model
subTest$classe <- as.factor(subTest$classe)
predictionDT <- as.factor(predictionDT)
confusionMatrix(subTest$classe, predictionDT)
#DECISION TREE
library(rpart)
library(randomForest)
set.seed(555)
rfGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1)
modelFit <- randomForest(classe ~., data = subTrain, tuneGrid = rfGrid)
#DECISION TREE
library(rpart)
library(randomForest)
set.seed(555)
rfGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1)
modelFit <- randomForest(classe ~ ., data = subTrain, tuneGrid = rfGrid)
#DECISION TREE
library(rpart)
library(randomForest)
set.seed(555)
rfGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1)
modelFit <- randomForest((classe ~ .),  subTrain, tuneGrid = rfGrid)
#DECISION TREE
library(rpart)
library(randomForest)
set.seed(555)
rfGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1)
subTrain <- as.factor(subTrain)
modelFit <- randomForest(classe ~ .,  subTrain, tuneGrid = rfGrid)
# Split the training data in training (75%) and testing (25%) data subset
library(caret)
inTrain <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
subTrain <- train[inTrain, ]
subTest <- train[-inTrain, ]
dim(subTrain)
dim(subTest)
#DECISION TREE
library(rpart)
library(randomForest)
set.seed(555)
rfGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1)
subTrain <- as.factor(subTrain)
modelFit <- randomForest(classe ~ .,  subTrain, tuneGrid = rfGrid)
# Split the training data in training (75%) and testing (25%) data subset
library(caret)
inTrain <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
subTrain <- train[inTrain, ]
subTest <- train[-inTrain, ]
dim(subTrain)
dim(subTest)
View(subTrain)
library(knitr)
# Downloading the data
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#download.file(trainUrl, destfile = "./train.csv", method = "curl")
#download.file(testUrl, destfile = "./test.csv", method = "curl")
# Reading the data and filling missing data
train <- read.csv("./train.csv",na.strings = c("NA", "#DIV/0!"))
test <- read.csv("./test.csv",na.strings = c("NA", "#DIV/0!"))
kable(head(train))
kable(head(test))
# Getting the dimensions of the dataframe
dim(train)
dim(test)
# Remove variables with near zero variance
train<-train[,colSums(is.na(train)) == 0]
test <-test[,colSums(is.na(test)) == 0]
# Remove the first 7 columns which are not used in the prediction model
train   <-train[,-c(1:7)]
test <-test[,-c(1:7)]
# Dimensions of the data after cleaning
dim(train)
dim(test)
# Split the training data in training (75%) and testing (25%) data subset
library(caret)
inTrain <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
subTrain <- train[inTrain, ]
subTest <- train[-inTrain, ]
dim(subTrain)
dim(subTest)
#DECISION TREE
library(rpart)
library(randomForest)
set.seed(555)
rfGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1)
subTrain$classe <- as.factor(subTrain$classe)
modelFit <- randomForest(classe ~ .,  subTrain, tuneGrid = rfGrid)
print(modelFit)
plot(modelFit)
# Perform prediction
predictSubmission <- predict(fitRF, testing, type="class")
# Random Forest
library(rpart)
library(randomForest)
set.seed(555)
rfGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1)
subTrain$classe <- as.factor(subTrain$classe)
modelFit <- randomForest(classe ~ .,  subTrain, tuneGrid = rfGrid)
print(modelFit)
plot(modelFit)
# Testing the sub test data
predictions <- predict(modelFit, newdata = subTest)
subTest$classe <- as.factor(subTest$classe)
confusionMatrix(predictions, subTest$classe)
# Testing the sub test data
predictions <- predict(modelFit, newdata = subTest)
subTest$classe <- as.factor(subTest$classe)
kable(confusionMatrix(predictions, subTest$classe))
# Testing the sub test data
predictions <- predict(modelFit, newdata = subTest)
subTest$classe <- as.factor(subTest$classe)
confusionMatrix(predictions, subTest$classe)
knitr::opts_chunk$set(comment = NA)
# Testing the sub test data
predictions <- predict(modelFit, newdata = subTest)
subTest$classe <- as.factor(subTest$classe)
confusionMatrix(predictions, subTest$classe)
# Test validation sample
answers <- predict(modelFit, newdata = test, type = "response")
print(answers)
# Test validation sample
answers <- predict(modelFit, newdata = test, type = "response")
print(t.answers)
# Test validation sample
answers <- predict(modelFit, newdata = test, type = "response")
answers <- t.answers
# Test validation sample
answers <- predict(modelFit, newdata = test, type = "response")
print(answers)
